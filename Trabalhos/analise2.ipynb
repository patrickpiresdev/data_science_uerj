{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24a9ac98",
   "metadata": {},
   "source": [
    "# Avaliação 2\n",
    "\n",
    "- Aluno: Patrick Pires\n",
    "- Matrícula: 201810037211"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee049154",
   "metadata": {},
   "source": [
    "## Enunciado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393c54fb",
   "metadata": {},
   "source": [
    "A partir da base de dados enviada e do estudo sobre pré-processamentos feitos na primeira parte do trabalho (corrigindo os problemas identificados na avaliação e a execução da seleção de variáveis para os que não avaliaram), apresentar novos resultados utilizando o modelo Decision Tree (DT), kNN e Naive Bayes e acrescente um outro algoritmo (pode ser ensemble ou redes neural, por exemplo) e discutir seus resultados, seguindo os processos para Data Mining.\n",
    "\n",
    "\n",
    "Salve o nome do arquivo relatório com o sobrenome dos participantes em pdf e envie para o email karla.figueiredo@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf8f8e",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d2c824",
   "metadata": {},
   "source": [
    "No trabalho anterior pude fazer uma análise exploratória na base de dados para a entender melhor. Só para lembrar, irei adicionar abaixo o resumo feito sobre a base de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ad9e6c",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c78b40b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, make_scorer, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import KBinsDiscretizer, LabelEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7cf6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atributo</th>\n",
       "      <th>tipo</th>\n",
       "      <th>valores faltantes</th>\n",
       "      <th>outliers</th>\n",
       "      <th>cardinalidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>quantitativo racional</td>\n",
       "      <td>0</td>\n",
       "      <td>não</td>\n",
       "      <td>discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sex</td>\n",
       "      <td>qualitativa nominal</td>\n",
       "      <td>0</td>\n",
       "      <td>n/a</td>\n",
       "      <td>discreta (binária)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Job</td>\n",
       "      <td>qualitativa ordinal</td>\n",
       "      <td>0</td>\n",
       "      <td>n/a</td>\n",
       "      <td>discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Housing</td>\n",
       "      <td>qualitativa nominal</td>\n",
       "      <td>0</td>\n",
       "      <td>n/a</td>\n",
       "      <td>discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saving accounts</td>\n",
       "      <td>qualitativa ordinal</td>\n",
       "      <td>183</td>\n",
       "      <td>n/a</td>\n",
       "      <td>discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Checking account</td>\n",
       "      <td>qualitativa ordinal</td>\n",
       "      <td>394</td>\n",
       "      <td>n/a</td>\n",
       "      <td>discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Credit amount</td>\n",
       "      <td>quantitativo racional</td>\n",
       "      <td>0</td>\n",
       "      <td>não</td>\n",
       "      <td>contínua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Duration</td>\n",
       "      <td>quantitativo racional</td>\n",
       "      <td>0</td>\n",
       "      <td>não</td>\n",
       "      <td>discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Purpose</td>\n",
       "      <td>qualitativa nominal</td>\n",
       "      <td>0</td>\n",
       "      <td>n/a</td>\n",
       "      <td>discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Risk</td>\n",
       "      <td>qualitativa nominal</td>\n",
       "      <td>0</td>\n",
       "      <td>n/a</td>\n",
       "      <td>discreta (binária)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           atributo                   tipo  valores faltantes outliers  \\\n",
       "0               Age  quantitativo racional                  0      não   \n",
       "1               Sex    qualitativa nominal                  0      n/a   \n",
       "2               Job    qualitativa ordinal                  0      n/a   \n",
       "3           Housing    qualitativa nominal                  0      n/a   \n",
       "4   Saving accounts    qualitativa ordinal                183      n/a   \n",
       "5  Checking account    qualitativa ordinal                394      n/a   \n",
       "6     Credit amount  quantitativo racional                  0      não   \n",
       "7          Duration  quantitativo racional                  0      não   \n",
       "8           Purpose    qualitativa nominal                  0      n/a   \n",
       "9              Risk    qualitativa nominal                  0      n/a   \n",
       "\n",
       "        cardinalidade  \n",
       "0            discreta  \n",
       "1  discreta (binária)  \n",
       "2            discreta  \n",
       "3            discreta  \n",
       "4            discreta  \n",
       "5            discreta  \n",
       "6            contínua  \n",
       "7            discreta  \n",
       "8            discreta  \n",
       "9  discreta (binária)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumo_df = pd.DataFrame({\n",
    "    'atributo': ['Age', 'Sex', 'Job', 'Housing', 'Saving accounts',\n",
    "                 'Checking account', 'Credit amount', 'Duration', 'Purpose', 'Risk'],\n",
    "    'tipo': ['quantitativo racional', 'qualitativa nominal', 'qualitativa ordinal',\n",
    "             'qualitativa nominal', 'qualitativa ordinal', 'qualitativa ordinal',\n",
    "             'quantitativo racional', 'quantitativo racional', 'qualitativa nominal', 'qualitativa nominal'],\n",
    "    'valores faltantes': [0, 0, 0, 0, 183, 394, 0, 0, 0, 0],\n",
    "    'outliers': ['não', 'n/a', 'n/a', 'n/a', 'n/a', 'n/a', 'não', 'não', 'n/a', 'n/a'],\n",
    "    'cardinalidade': ['discreta', 'discreta (binária)', 'discreta', 'discreta',\n",
    "                      'discreta', 'discreta', 'contínua', 'discreta', 'discreta', 'discreta (binária)']\n",
    "})\n",
    "resumo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a09a88",
   "metadata": {},
   "source": [
    "## Avaliação dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15832d5f",
   "metadata": {},
   "source": [
    "Irei avaliar 4 modelos: Árvore de Decisão, KNN, Naive Bayes e Redes Neurais. A avaliação será feita da seguinte maneira:\n",
    "- Avaliação dos modelos mais simples entre si, i.e., do jeito que o `sklearn` os fornece.\n",
    "- Avaliação dos modelos com melhores hiperparâmetros. Realizando uma busca em grade (`GridSearchCV`).\n",
    "- Avaliação dos modelos com os melhores hiperparâmetros e preenchimento de \"missing values\" com a moda.\n",
    "    - Irei optar pela estratégia de preencher os \"missing values\" e não remover linhas pelo mesmo aspecto discutido no trabalho anterior: há poucos registros e, além disso, ao remover linhas com registros faltantes, o desbalanceamento entre as classes acaba sendo perdido e o modelo não aprenderá de forma a refletir a realidade dos dados e sua distribuição.\n",
    "\n",
    "### Critério de Avaliação\n",
    "\n",
    "Quero que o modelo acerte mais na classificação de pessoas que são más (`bad`) devedoras. Isso para garantir que o modelo não diga que uma pessoa é boa devedora, i.e., pagará seu empréstimo, quando a pessoa não é e não pagará. Dessa forma, diminui as chances de sair no prejuízo.\n",
    "Claro que não posso deixar de observar também a classificação dos bons (`good`) devedores, pois se o modelo os classifica errado, é dinheiro que deixa de entrar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08817107",
   "metadata": {},
   "source": [
    "## Definindo as funções a serem utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61f4faf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_with_mode(df, column):\n",
    "    '''\n",
    "    Preenche valores faltantes de uma coluna com a moda, de acordo com a proporção da coluna alvo ('Risk').\n",
    "    '''\n",
    "\n",
    "    goods_filter = df['Risk'] == 'good'\n",
    "    bads_filter = df['Risk'] == 'bad'\n",
    "\n",
    "    goods = df[goods_filter]\n",
    "    bads = df[bads_filter]\n",
    "\n",
    "    good_mode = goods[column].mode()[0]\n",
    "    bad_mode = bads[column].mode()[0]\n",
    "\n",
    "    df.loc[goods_filter, column] = df.loc[goods_filter, column].fillna(good_mode)\n",
    "    df.loc[bads_filter, column] = df.loc[bads_filter, column].fillna(bad_mode)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def handle_missing(df, column, with_mode=False):\n",
    "    '''\n",
    "    Lida com o preenchimento de valores faltantes de uma dada coluna. Ou preenche com a moda, ou com o valor 'missing'.\n",
    "    '''\n",
    "\n",
    "    new_df = df.copy()\n",
    "\n",
    "    if with_mode:\n",
    "        return fill_with_mode(new_df, column)\n",
    "\n",
    "    new_df[column] = new_df[column].fillna('missing')\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea478d3c",
   "metadata": {},
   "source": [
    "### Funções de preparação dos dados de acordo com o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c02f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dt_prepare(df, fill_missing_with_mode=False):\n",
    "    new_df = df.copy()\n",
    "\n",
    "    new_df = handle_missing(new_df, 'Saving accounts', with_mode=fill_missing_with_mode)\n",
    "    new_df = handle_missing(new_df, 'Checking account', with_mode=fill_missing_with_mode)\n",
    "\n",
    "    categorical_nominal_cols = resumo_df[resumo_df['tipo'] == 'qualitativa nominal']['atributo'].tolist()\n",
    "    categorical_ordinal_cols = resumo_df[resumo_df['tipo'] == 'qualitativa ordinal']['atributo'].tolist()\n",
    "\n",
    "    categorical_nominal_cols.remove('Risk')  # 'Risk' is the target variable\n",
    "\n",
    "    # handle using one-hot encoding for nominal categorical variables\n",
    "    new_df = pd.get_dummies(new_df, columns=categorical_nominal_cols)\n",
    "\n",
    "    # handle using ordinal encoding for ordinal categorical variables\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    new_df[categorical_ordinal_cols] = ordinal_encoder.fit_transform(new_df[categorical_ordinal_cols])\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def knn_prepare(df, fill_missing_with_mode=False):\n",
    "    new_df = df.copy()\n",
    "\n",
    "    # preparacao de dados para a arvore de decisao\n",
    "    new_df = handle_missing(new_df, 'Saving accounts', with_mode=fill_missing_with_mode)\n",
    "    new_df = handle_missing(new_df, 'Checking account', with_mode=fill_missing_with_mode)\n",
    "\n",
    "    categorical_nominal_cols = resumo_df[resumo_df['tipo'] == 'qualitativa nominal']['atributo'].tolist()\n",
    "    categorical_ordinal_cols = resumo_df[resumo_df['tipo'] == 'qualitativa ordinal']['atributo'].tolist()\n",
    "    numerical_cols = resumo_df[resumo_df['tipo'].str.contains('quantitativo')]['atributo'].tolist()\n",
    "\n",
    "    categorical_nominal_cols.remove('Risk')  # 'Risk' is the target variable\n",
    "\n",
    "    # handle using one-hot encoding for nominal categorical variables\n",
    "    new_df = pd.get_dummies(new_df, columns=categorical_nominal_cols)\n",
    "\n",
    "    # handle using ordinal encoding for ordinal categorical variables\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    new_df[categorical_ordinal_cols] = ordinal_encoder.fit_transform(new_df[categorical_ordinal_cols])\n",
    "\n",
    "    # handle using standard scaling for numerical variables\n",
    "    scaler = StandardScaler()\n",
    "    new_df[numerical_cols] = scaler.fit_transform(new_df[numerical_cols])\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def nb_prepare(df, fill_missing_with_mode=False):\n",
    "    new_df = df.copy()\n",
    "\n",
    "    new_df = handle_missing(new_df, 'Saving accounts', with_mode=fill_missing_with_mode)\n",
    "    new_df = handle_missing(new_df, 'Checking account', with_mode=fill_missing_with_mode)\n",
    "\n",
    "    categorical_nominal_cols = resumo_df[resumo_df['tipo'] == 'qualitativa nominal']['atributo'].tolist()\n",
    "    categorical_ordinal_cols = resumo_df[resumo_df['tipo'] == 'qualitativa ordinal']['atributo'].tolist()\n",
    "    continuous_cols = resumo_df[resumo_df['cardinalidade'] == 'contínua']['atributo'].tolist()\n",
    "\n",
    "    # handle using label encoding for nominal categorical variables\n",
    "    for col in categorical_nominal_cols:\n",
    "        label_encoder = LabelEncoder()\n",
    "        new_df[col] = label_encoder.fit_transform(new_df[col])\n",
    "\n",
    "    # handle using ordinal encoding for ordinal categorical variables\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    new_df[categorical_ordinal_cols] = ordinal_encoder.fit_transform(new_df[categorical_ordinal_cols])\n",
    "    new_df[categorical_ordinal_cols].astype(int)\n",
    "\n",
    "    # handle using KBinsDiscretizer for continuous variables\n",
    "    discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "    new_df[continuous_cols] = discretizer.fit_transform(new_df[continuous_cols])\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def nn_prepare(df, fill_missing_with_mode=False):\n",
    "    new_df = df.copy()\n",
    "\n",
    "    new_df = handle_missing(new_df, 'Saving accounts', with_mode=fill_missing_with_mode)\n",
    "    new_df = handle_missing(new_df, 'Checking account', with_mode=fill_missing_with_mode)\n",
    "\n",
    "    categorical_nominal_cols = resumo_df[resumo_df['tipo'] == 'qualitativa nominal']['atributo'].tolist()\n",
    "    categorical_ordinal_cols = resumo_df[resumo_df['tipo'] == 'qualitativa ordinal']['atributo'].tolist()\n",
    "    numerical_cols = resumo_df[resumo_df['tipo'].str.contains('quantitativo')]['atributo'].tolist()\n",
    "    \n",
    "    categorical_nominal_cols.remove('Risk')  # 'Risk' is the target variable\n",
    "    \n",
    "    # handle using one-hot encoding for nominal categorical variables\n",
    "    new_df = pd.get_dummies(new_df, columns=categorical_nominal_cols)\n",
    "    \n",
    "    # handle using ordinal encoding for ordinal categorical variables\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    new_df[categorical_ordinal_cols] = ordinal_encoder.fit_transform(new_df[categorical_ordinal_cols])\n",
    "\n",
    "    # handle using standard scaling for numerical variables\n",
    "    scaler = StandardScaler()\n",
    "    new_df[numerical_cols] = scaler.fit_transform(new_df[numerical_cols])\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642c4871",
   "metadata": {},
   "source": [
    "Definirei um dicionário onde posso acessar as funções de preparação dos dados de acordo com o modelo que quero utilizar. Isso para que a execução do experimento não fique repetitiva e eu possa facilmente trocar o modelo a ser utilizado. Na definição da função que executa experimentos, isso ficará mais claro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47af3245",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare = {\n",
    "    'dt': dt_prepare,\n",
    "    'knn': knn_prepare,\n",
    "    'nb': nb_prepare,\n",
    "    'nn': nn_prepare\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ecacf2",
   "metadata": {},
   "source": [
    "Farei o mesmo com a definição dos hiperparâmetros de cada modelo, pelo mesmo motivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de83a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_param_grid = {\n",
    "    'max_depth': [2, 4, 8, 16, 32, 64, None],\n",
    "    'min_samples_split': [2, 4, 8, 16, 32, 64],\n",
    "    'min_samples_leaf': [1, 2, 4, 8, 16, 32, 64]\n",
    "}\n",
    "\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "}\n",
    "\n",
    "nb_param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7]\n",
    "}\n",
    "\n",
    "nn_param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50)]\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'dt': dt_param_grid,\n",
    "    'knn': knn_param_grid,\n",
    "    'nb': nb_param_grid,\n",
    "    'nn': nn_param_grid\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4acf67",
   "metadata": {},
   "source": [
    "Abaixo, uma função que encontra o melhor modelo para o conjunto de dados fornecido, utilizando GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9903e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(model, df, scorer, model_acronym):\n",
    "    '''\n",
    "    Encontra o melhor modelo para o conjunto de dados fornecido, utilizando GridSearchCV.\n",
    "    '''\n",
    "\n",
    "    new_df = prepare[model_acronym](df)\n",
    "\n",
    "    X = new_df.drop(columns=['Risk'], axis=1)\n",
    "    y = new_df['Risk']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    param_grid = param_grids[model_acronym]\n",
    "    dt_grid_search = GridSearchCV(model, param_grid, cv=5, scoring=scorer, n_jobs=-1)\n",
    "    dt_grid_search.fit(X_train, y_train)\n",
    "\n",
    "    return dt_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a004bfda",
   "metadata": {},
   "source": [
    "Agora sim a função que executa o experimento de fato. Essa função foi escrita com o objetivo de poder executar cada um dos cenários que propus para serem avaliados, i.e.:\n",
    "\n",
    "1. Com o modelo cru (do jeito que o sklearn fornece)\n",
    "2. Com os melhores hiperparâmetros encontrados\n",
    "3. Com os melhores hiperparâmetros encontrados e preenchendo os valores faltantes com a moda da coluna.\n",
    "\n",
    "Para isso a função recebe alguns parâmetros:\n",
    "\n",
    "- `use_best`: utilizada para dizer se o experimento deve utilizar o modelo com os melhores hiperparâmetros encontrados ou o modelo passado para o experimento (que será o modelo simples, padrão do `sklearn`).\n",
    "- `pos_label`: utilizado para definir qual o rótulo a ser utilizado na métrica\n",
    "- `fill_missing_with_mode`: utilizado para definir se os valores faltantes devem ser preenchidos com a moda da coluna.\n",
    "- `model_acronym`: utilizado para definir qual o modelo a ser utilizado no experimento. Isso para que a função possa acessar o dicionário de funções de preparação dos dados e o dicionário de hiperparâmetros do modelo.\n",
    "\n",
    "Dessa forma, para executar cada experimento que desejo basta passar os valores da seguinte maneira:\n",
    "\n",
    "1. `use_best=False`, `fill_missing_with_mode=False`\n",
    "2. `use_best=True`, `fill_missing_with_mode=False`\n",
    "3. `use_best=True`, `fill_missing_with_mode=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fac98b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def execute_experiment(model, df, model_acronym, use_best=True, scorer=None, pos_label='bad', show_confusion_matrix=True, fill_missing_with_mode=False):\n",
    "    new_df = prepare[model_acronym](df, fill_missing_with_mode=fill_missing_with_mode)\n",
    "\n",
    "    X = new_df.drop(columns=['Risk'], axis=1)\n",
    "    y = new_df['Risk']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    if use_best:\n",
    "        model = find_best_model(model, df, scorer, model_acronym)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if show_confusion_matrix:\n",
    "        ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
    "        plt.title(f'{model_acronym} confusion matrix')\n",
    "        plt.show()\n",
    "    \n",
    "    return recall_score(y_test, y_pred, pos_label=pos_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560d0768",
   "metadata": {},
   "source": [
    "#### Experimento 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5b7ec95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('class_german_credit.csv')\n",
    "\n",
    "# dicionário para armazenar os recalls de cada modelo em cada experimento\n",
    "recalls = {\n",
    "    'dt': [],\n",
    "    'knn': [],\n",
    "    'nb': [],\n",
    "    'nn': []\n",
    "}\n",
    "\n",
    "experiments_defs = [\n",
    "    {'model': DecisionTreeClassifier(random_state=42), 'df': df, 'model_acronym': 'dt', 'show_confusion_matrix': False},\n",
    "    {'model': KNeighborsClassifier(), 'df': df, 'model_acronym': 'knn', 'show_confusion_matrix': False},\n",
    "    {'model': GaussianNB(), 'df': df, 'model_acronym': 'nb', 'show_confusion_matrix': False, 'pos_label': 0},\n",
    "    {'model': MLPClassifier(random_state=42), 'df': df, 'model_acronym': 'nn', 'show_confusion_matrix': False}\n",
    "]\n",
    "\n",
    "def execute_experiments(experiments_defs, recalls):\n",
    "    for experiment in experiments_defs:\n",
    "        model_acronym = experiment['model_acronym']\n",
    "        recall = execute_experiment(**experiment)\n",
    "        recall = f'{int(recall*100)}%'\n",
    "        recalls[model_acronym].append(recall)\n",
    "\n",
    "execute_experiments(experiments_defs, recalls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac9324",
   "metadata": {},
   "source": [
    "#### Experimento 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ed6c260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scorer = make_scorer(recall_score, pos_label='bad')\n",
    "scorer2 = make_scorer(recall_score, pos_label=0)\n",
    "\n",
    "experiments_defs = [\n",
    "    {'model': DecisionTreeClassifier(random_state=42), 'df': df, 'model_acronym': 'dt', 'use_best': True, 'scorer': scorer, 'show_confusion_matrix': False},\n",
    "    {'model': KNeighborsClassifier(), 'df': df, 'model_acronym': 'knn', 'use_best': True, 'scorer': scorer, 'show_confusion_matrix': False},\n",
    "    {'model': GaussianNB(), 'df': df, 'model_acronym': 'nb', 'pos_label': 0, 'use_best': True, 'scorer': scorer2, 'show_confusion_matrix': False},\n",
    "    {'model': MLPClassifier(random_state=42), 'df': df, 'model_acronym': 'nn', 'use_best': True, 'scorer': scorer, 'show_confusion_matrix': False}\n",
    "]\n",
    "\n",
    "execute_experiments(experiments_defs, recalls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611dc547",
   "metadata": {},
   "source": [
    "#### Experimento 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a2d0f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/patrick/documents/projects/data_science/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "experiments_defs = [\n",
    "    {'model': DecisionTreeClassifier(random_state=42), 'df': df, 'model_acronym': 'dt', 'use_best': True, 'scorer': scorer, 'show_confusion_matrix': False, 'fill_missing_with_mode': True},\n",
    "    {'model': KNeighborsClassifier(), 'df': df, 'model_acronym': 'knn', 'use_best': True, 'scorer': scorer, 'show_confusion_matrix': False, 'fill_missing_with_mode': True},\n",
    "    {'model': GaussianNB(), 'df': df, 'model_acronym': 'nb', 'pos_label': 0, 'use_best': True, 'scorer': scorer2, 'show_confusion_matrix': False, 'fill_missing_with_mode': True},\n",
    "    {'model': MLPClassifier(random_state=42), 'df': df, 'model_acronym': 'nn', 'use_best': True, 'scorer': scorer, 'show_confusion_matrix': False, 'fill_missing_with_mode': True}\n",
    "]\n",
    "\n",
    "execute_experiments(experiments_defs, recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f1ed39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>knn</th>\n",
       "      <th>nb</th>\n",
       "      <th>nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38%</td>\n",
       "      <td>16%</td>\n",
       "      <td>28%</td>\n",
       "      <td>33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44%</td>\n",
       "      <td>27%</td>\n",
       "      <td>28%</td>\n",
       "      <td>33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37%</td>\n",
       "      <td>27%</td>\n",
       "      <td>37%</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dt  knn   nb   nn\n",
       "0  38%  16%  28%  33%\n",
       "1  44%  27%  28%  33%\n",
       "2  37%  27%  37%  35%"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(recalls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec4ddf5",
   "metadata": {},
   "source": [
    "O que pode ser observado para cada modelo:\n",
    "\n",
    "- decision tree:\n",
    "    - ao fazer a busca em grade: melhorou\n",
    "    - ao preencher os valores faltantes com a moda: piorou\n",
    "- knn:\n",
    "    - busca em grade: melhorou\n",
    "    - preencher os valores faltantes: não mudou\n",
    "- naive bayes:\n",
    "    - busca em grade: não mudou\n",
    "    - preencher os valores faltantes: melhorou\n",
    "- rede neural:\n",
    "    - busca em grade: não mudou\n",
    "    - preencher os valores faltantes: melhorou\n",
    "\n",
    "Dentre todos esses modelos e estratégias, o que melhor se adequou ao que preciso foi a árvore de decisão com os melhores hiperparâmetros encontrados, mas sem o preenchimento dos valores faltantes com a moda. Talvez com uma estratégia de preenchimento diferente, o resultado fosse melhor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
