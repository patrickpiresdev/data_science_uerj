{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e266c9",
   "metadata": {},
   "source": [
    "# Exercício 1\n",
    "\n",
    "- Aluno: Patrick Pires\n",
    "- Matrícula: 201810037211\n",
    "\n",
    "## Enunciado\n",
    "\n",
    "A partir da base de dados:\n",
    "\n",
    "- Parte 1: Descreva a base de dados descrendo os atributos, numéricos e categóricos, classificando segundo a escala (nominal ou razão) e a cardinalidade (discreta, contínua, binária).\n",
    "\n",
    "- Parte 2: Descreva cada um dos atributos segundo frequência, mínimo e máximo valor, dia desvios padrão, conforme o caso.\n",
    "\n",
    "- Parte 3: Avalie os resultados dos processos abaixo, caso sejam utilizados na base de dados, após o processo de classificação com DT ter sido utilizado.\n",
    "    - limpeza de dados (outlier, missing)\n",
    "    - normalização/transformação\n",
    "    - discretização\n",
    "\n",
    "## Parte 1\n",
    "\n",
    "Para entender melhor sobre os dados e conseguir classificá-los e descrevê-los, irei fazer uma análise dos mesmos junto a sua descrição fornecida em `dataset_description.txt`.\n",
    "\n",
    "#### Descrição\n",
    "\n",
    "https://www.kaggle.com/uciml/german-credit\n",
    "\n",
    "Context\n",
    "\n",
    "The original dataset contains 1000 entries with 20 categorial/symbolic attributes prepared by Prof. Hofmann. In this dataset, each entry represents a person who takes a credit by a bank. Each person is classified as good or bad credit risks according to the set of attributes. The link to the original dataset can be found below.\n",
    "\n",
    "Content\n",
    "\n",
    "It is almost impossible to understand the original dataset due to its complicated system of categories and symbols. Thus, I wrote a small Python script to convert it into a readable CSV file. Several columns are simply ignored, because in my opinion either they are not important or their descriptions are obscure. The selected attributes are:\n",
    "\n",
    "- Age (numeric)\n",
    "- Sex (text: male, female)\n",
    "- Job (numeric: 0 - unskilled and non-resident, 1 - unskilled and resident, 2 - skilled, 3 - highly skilled)\n",
    "- Housing (text: own, rent, or free)\n",
    "- Saving accounts (text - little, moderate, quite rich, rich)\n",
    "- Checking account (numeric, in DM - Deutsch Mark)\n",
    "- Credit amount (numeric, in DM)\n",
    "- Duration (numeric, in month)\n",
    "- Purpose (text: car, furniture/equipment, radio/TV, domestic appliances, repairs, education, business, vacation/others)\n",
    "\n",
    "\n",
    "#### Panorama dos dados\n",
    "\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('class_german_credit.csv')\n",
    "df.info()\n",
    "```\n",
    "\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    RangeIndex: 1000 entries, 0 to 999\n",
    "    Data columns (total 10 columns):\n",
    "     #   Column            Non-Null Count  Dtype \n",
    "    ---  ------            --------------  ----- \n",
    "     0   Age               1000 non-null   int64 \n",
    "     1   Sex               1000 non-null   object\n",
    "     2   Job               1000 non-null   int64 \n",
    "     3   Housing           1000 non-null   object\n",
    "     4   Saving accounts   817 non-null    object\n",
    "     5   Checking account  606 non-null    object\n",
    "     6   Credit amount     1000 non-null   int64 \n",
    "     7   Duration          1000 non-null   int64 \n",
    "     8   Purpose           1000 non-null   object\n",
    "     9   Risk              1000 non-null   object\n",
    "    dtypes: int64(4), object(6)\n",
    "    memory usage: 78.3+ KB\n",
    "\n",
    "\n",
    "Como uma breve interpretação desse resumo dos dados, já podemos ver que há valores faltantes (*missing*) para os atributos `Saving accounts` e `Checking account`.\n",
    "\n",
    "Além disso, na descrição dada por `dataset_description.txt`, o atributo `Checking account` é dito como numérico, mas acima é dito como `object`, não um tipo numérico como era de se esperar.\n",
    "\n",
    "Para obter mais informações relevantes acerca dos dado, irei realizar uma análise exploratória sobre cada atributo individualmente.\n",
    "\n",
    "### Age\n",
    "\n",
    "Pela descrição em `dataset_description.txt` e no resumo do dataframe, podemos ver que é um dado numérico/quantitativo. Agora irei explorar para obter mais informações desse atributo.\n",
    "\n",
    "\n",
    "```python\n",
    "print('--------- descrição estatística ---------')\n",
    "print(df['Age'].describe())\n",
    "\n",
    "print('\\n--------- valores faltantes ---------')\n",
    "print(df[df['Age'].isnull()])\n",
    "```\n",
    "\n",
    "    --------- descrição estatística ---------\n",
    "    count    1000.000000\n",
    "    mean       35.546000\n",
    "    std        11.375469\n",
    "    min        19.000000\n",
    "    25%        27.000000\n",
    "    50%        33.000000\n",
    "    75%        42.000000\n",
    "    max        75.000000\n",
    "    Name: Age, dtype: float64\n",
    "    \n",
    "    --------- valores faltantes ---------\n",
    "    Empty DataFrame\n",
    "    Columns: [Age, Sex, Job, Housing, Saving accounts, Checking account, Credit amount, Duration, Purpose, Risk]\n",
    "    Index: []\n",
    "\n",
    "\n",
    "Como pode ser observado acima, o atributo `Age` se classifica como **quantitativo discreto** e seu nível (escala) de mensuração é **racional**.\n",
    "\n",
    "Além disso, claramente não há valores faltantes (*missing*) por terem $1000$ valores dentre $1000$ registros e nenhum deles ser nulo.\n",
    "\n",
    "Podemos perceber também que não há valores discrepantes (*outliers*) por seus valores mínimo e máximo serem, respectivamente, $19$ e $75$.\n",
    "\n",
    "### Sex\n",
    "\n",
    "Pela descrição em `dataset_description.txt` e no resumo do dataframe, podemos ver que é um dado do tipo texto e que assume apenas dois valores `male` (*masculino*) e `female` (*feminino*).\n",
    "\n",
    "\n",
    "```python\n",
    "df['Sex'].value_counts(dropna=False).sort_index()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Sex\n",
    "    female    310\n",
    "    male      690\n",
    "    Name: count, dtype: int64\n",
    "\n",
    "\n",
    "\n",
    "Como observado acima, o atributo, de fato, assume os dois valores (ou categorias) mencionados anteriormente, com isso se classifica como **quantitativa nominal**.\n",
    "\n",
    "Além disso, somando as frequências temos $1000$ valores aparecendo nesse atributo sendo que nenhum deles é nulo, então não há valores faltantes (*missing*).\n",
    "\n",
    "### Job\n",
    "\n",
    "Pela descrição em `dataset_description.txt` e no resumo do dataframe, podemos ver que é um dado do tipo categórico, apesar de ser representado de forma numérica.\n",
    "\n",
    "\n",
    "```python\n",
    "df['Job'].value_counts(dropna=False).sort_index()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Job\n",
    "    0     22\n",
    "    1    200\n",
    "    2    630\n",
    "    3    148\n",
    "    Name: count, dtype: int64\n",
    "\n",
    "\n",
    "\n",
    "Não é possível identificar muito bem as frequências sem consultar o mapeamento em `dataset_description.txt`. Para facilitar a leitura irei fazer o mapeamento direto na contagem de valores.\n",
    "\n",
    "Mas antes disso, já é possível dizer que se trata de um dado **qualitativo ordinal** e que não há valores faltantes.\n",
    "\n",
    "\n",
    "```python\n",
    "job_titles = {\n",
    "    0: 'Unskilled and non-resident',\n",
    "    1: 'Unskilled and resident',\n",
    "    2: 'Skilled',\n",
    "    3: 'Highly skilled'\n",
    "}\n",
    "job_counts = df['Job'].value_counts().sort_index()\n",
    "job_counts.index = job_counts.index.map(job_titles)\n",
    "job_counts\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Job\n",
    "    Unskilled and non-resident     22\n",
    "    Unskilled and resident        200\n",
    "    Skilled                       630\n",
    "    Highly skilled                148\n",
    "    Name: count, dtype: int64\n",
    "\n",
    "\n",
    "\n",
    "> Dúvida para investigar: para árvore de decisão, esse campo deverá/poderá permanecer numérico ou deverá ser textual?\n",
    "\n",
    "> R.: Por essa variável ser ordinal e seus valores estarem adequados com as categorias, i.e., 0 representa o menos qualidicado e 3, o mais qualificado (segue a ordem do menor para o maior), o modelo conseguirá interpretá-la da maneira correta. O problema seria se fosse nominal. O modelo poderia entender que existe uma ordem e certa distância entre as categorias por serem números.\n",
    "\n",
    "### Housing\n",
    "\n",
    "Pela descrição em `dataset_description.txt` e no resumo do dataframe, podemos ver que é um dado do tipo categórico.\n",
    "\n",
    "\n",
    "```python\n",
    "df['Housing'].value_counts(dropna=False).sort_index()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Housing\n",
    "    free    108\n",
    "    own     713\n",
    "    rent    179\n",
    "    Name: count, dtype: int64\n",
    "\n",
    "\n",
    "\n",
    "Pode-se ver que é um atributo do tipo **qualitativo nominal** e que não há valores faltantes, pois a soma das frequências acima é $1000$.\n",
    "\n",
    "### Saving account\n",
    "\n",
    "Pela descrição em `dataset_description.txt` e no resumo do dataframe, podemos ver que é um dado do tipo texto.\n",
    "\n",
    "\n",
    "```python\n",
    "df['Saving accounts'].value_counts(dropna=False).sort_index()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Saving accounts\n",
    "    little        603\n",
    "    moderate      103\n",
    "    quite rich     63\n",
    "    rich           48\n",
    "    NaN           183\n",
    "    Name: count, dtype: int64\n",
    "\n",
    "\n",
    "\n",
    "Temos um atributo do tipo **qualitativo ordinal** e que apresenta valores faltantes, 183 registros não apresentam valor para este atributo.\n",
    "\n",
    "### Checking Account\n",
    "\n",
    "Como mencionado anteriormente, esse campo é dito como numérico em `dataset_description.txt`, mas no resumo do dataframe é dito como `object`. Irei investigar seus possíveis valores para entender melhor como esse atributo se classifica de fato.\n",
    "\n",
    "\n",
    "```python\n",
    "df['Checking account'].value_counts(dropna=False).sort_index()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Checking account\n",
    "    little      274\n",
    "    moderate    269\n",
    "    rich         63\n",
    "    NaN         394\n",
    "    Name: count, dtype: int64\n",
    "\n",
    "\n",
    "\n",
    "Observando seus valores, podemos ver que é classificado como **qualitativo ordinal** e que há 394 valores faltantes.\n",
    "\n",
    "### Credit Amount\n",
    "\n",
    "Pela descrição em `dataset_description.txt` e no resumo do dataframe, podemos ver que é um dado do tipo numérico.\n",
    "\n",
    "\n",
    "```python\n",
    "print('\\n--------- descrição estatística ---------')\n",
    "print(df['Credit amount'].describe())\n",
    "print('\\n--------- valores faltantes ---------')\n",
    "print(df[df['Credit amount'].isnull()])\n",
    "```\n",
    "\n",
    "    \n",
    "    --------- descrição estatística ---------\n",
    "    count     1000.000000\n",
    "    mean      3271.258000\n",
    "    std       2822.736876\n",
    "    min        250.000000\n",
    "    25%       1365.500000\n",
    "    50%       2319.500000\n",
    "    75%       3972.250000\n",
    "    max      18424.000000\n",
    "    Name: Credit amount, dtype: float64\n",
    "    \n",
    "    --------- valores faltantes ---------\n",
    "    Empty DataFrame\n",
    "    Columns: [Age, Sex, Job, Housing, Saving accounts, Checking account, Credit amount, Duration, Purpose, Risk]\n",
    "    Index: []\n",
    "\n",
    "\n",
    "E pelo resumo acima pode-se ver que esse atributo é **quantitativo racional** e não tem valores faltantes.\n",
    "\n",
    "### Duration\n",
    "\n",
    "Pela descrição em `dataset_description.txt` e no resumo do dataframe, podemos ver que é um dado do tipo numérico.\n",
    "\n",
    "\n",
    "```python\n",
    "print('\\n--------- descrição estatística ---------')\n",
    "print(df['Duration'].describe())\n",
    "print('\\n--------- valores faltantes ---------')\n",
    "print(df[df['Duration'].isnull()])\n",
    "```\n",
    "\n",
    "    \n",
    "    --------- descrição estatística ---------\n",
    "    count    1000.000000\n",
    "    mean       20.903000\n",
    "    std        12.058814\n",
    "    min         4.000000\n",
    "    25%        12.000000\n",
    "    50%        18.000000\n",
    "    75%        24.000000\n",
    "    max        72.000000\n",
    "    Name: Duration, dtype: float64\n",
    "    \n",
    "    --------- valores faltantes ---------\n",
    "    Empty DataFrame\n",
    "    Columns: [Age, Sex, Job, Housing, Saving accounts, Checking account, Credit amount, Duration, Purpose, Risk]\n",
    "    Index: []\n",
    "\n",
    "\n",
    "E pelo resumo acima pode-se ver que esse atributo é **quantitativo racional** e não tem valores faltantes.\n",
    "\n",
    "### Purpose\n",
    "\n",
    "Pela descrição em `dataset_description.txt` e no resumo do dataframe, podemos ver que é um dado do tipo textual.\n",
    "\n",
    "\n",
    "```python\n",
    "df['Purpose'].value_counts(dropna=False).sort_index()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Purpose\n",
    "    business                97\n",
    "    car                    337\n",
    "    domestic appliances     12\n",
    "    education               59\n",
    "    furniture/equipment    181\n",
    "    radio/TV               280\n",
    "    repairs                 22\n",
    "    vacation/others         12\n",
    "    Name: count, dtype: int64\n",
    "\n",
    "\n",
    "\n",
    "Pode-se ver que se classifica como **qualitativo nominal** e não há valores faltantes.\n",
    "\n",
    "### Risk\n",
    "\n",
    "Por último, iremos avaliar a coluna que contém a informação que queremos que nosso modelo aprenda a inferir. Que diz se uma pessoa é boa (good) ou ruim (bad) com relação ao risco de crédito.\n",
    "\n",
    "\n",
    "```python\n",
    "df['Risk'].value_counts(dropna=False).sort_index()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Risk\n",
    "    bad     300\n",
    "    good    700\n",
    "    Name: count, dtype: int64\n",
    "\n",
    "\n",
    "\n",
    "Percebemos que é **qualitativa ordinal**, uma variável binária, que não tem valores faltantes, mas que está desbalanceada. Isso é um detalhe a ser considerado na hora de treinar o modelo.\n",
    "\n",
    "### Resumo\n",
    "\n",
    "Segue abaixo um resumo dos atributos.\n",
    "\n",
    "\n",
    "```python\n",
    "resumo_df = pd.DataFrame({\n",
    "    'atributo': ['Age', 'Sex', 'Job', 'Housing', 'Saving accounts',\n",
    "                 'Checking account', 'Credit amount', 'Duration', 'Purpose', 'Risk'],\n",
    "    'tipo': ['quantitativo racional', 'qualitativa nominal', 'qualitativa ordinal',\n",
    "             'qualitativa nominal', 'qualitativa ordinal', 'qualitativa ordinal',\n",
    "             'quantitativo racional', 'quantitativo racional', 'qualitativa nominal', 'qualitativa nominal'],\n",
    "    'valores faltantes': [0, 0, 0, 0, 183, 394, 0, 0, 0, 0],\n",
    "    'outliers': ['não', 'n/a', 'n/a', 'n/a', 'n/a', 'n/a', 'não', 'não', 'n/a', 'n/a'],\n",
    "    'cardinalidade': ['discreta', 'discreta (binária)', 'discreta', 'discreta',\n",
    "                      'discreta', 'discreta', 'contínua', 'discreta', 'discreta', 'discreta (binária)']\n",
    "})\n",
    "resumo_df\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>atributo</th>\n",
    "      <th>tipo</th>\n",
    "      <th>valores faltantes</th>\n",
    "      <th>outliers</th>\n",
    "      <th>cardinalidade</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>Age</td>\n",
    "      <td>quantitativo racional</td>\n",
    "      <td>0</td>\n",
    "      <td>não</td>\n",
    "      <td>discreta</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>Sex</td>\n",
    "      <td>qualitativa nominal</td>\n",
    "      <td>0</td>\n",
    "      <td>n/a</td>\n",
    "      <td>discreta (binária)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>Job</td>\n",
    "      <td>qualitativa ordinal</td>\n",
    "      <td>0</td>\n",
    "      <td>n/a</td>\n",
    "      <td>discreta</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>Housing</td>\n",
    "      <td>qualitativa nominal</td>\n",
    "      <td>0</td>\n",
    "      <td>n/a</td>\n",
    "      <td>discreta</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>Saving accounts</td>\n",
    "      <td>qualitativa ordinal</td>\n",
    "      <td>183</td>\n",
    "      <td>n/a</td>\n",
    "      <td>discreta</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>Checking account</td>\n",
    "      <td>qualitativa ordinal</td>\n",
    "      <td>394</td>\n",
    "      <td>n/a</td>\n",
    "      <td>discreta</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>6</th>\n",
    "      <td>Credit amount</td>\n",
    "      <td>quantitativo racional</td>\n",
    "      <td>0</td>\n",
    "      <td>não</td>\n",
    "      <td>contínua</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>7</th>\n",
    "      <td>Duration</td>\n",
    "      <td>quantitativo racional</td>\n",
    "      <td>0</td>\n",
    "      <td>não</td>\n",
    "      <td>discreta</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>8</th>\n",
    "      <td>Purpose</td>\n",
    "      <td>qualitativa nominal</td>\n",
    "      <td>0</td>\n",
    "      <td>n/a</td>\n",
    "      <td>discreta</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>9</th>\n",
    "      <td>Risk</td>\n",
    "      <td>qualitativa nominal</td>\n",
    "      <td>0</td>\n",
    "      <td>n/a</td>\n",
    "      <td>discreta (binária)</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "## Avaliação da Árvore de Decisão\n",
    "\n",
    "## Definindo as funções a serem utilizadas\n",
    "\n",
    "### Treinar uma árvore de decisão\n",
    "\n",
    "\n",
    "```python\n",
    "def trained_model(X_train, y_train, scorer, show_best_params=False, show_tree=False):\n",
    "    param_grid = {\n",
    "        'max_depth': [2, 4, 8, 16, 32, 64, None],\n",
    "        'min_samples_split': [2, 4, 8, 16, 32, 64],\n",
    "        'min_samples_leaf': [1, 2, 4, 8, 16, 32, 64]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        param_grid,\n",
    "        cv=5,  # 5-fold cross-validation\n",
    "        scoring=scorer,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    model = grid_search.best_estimator_\n",
    "\n",
    "    if show_best_params:\n",
    "        print('Melhores hiperparâmetros:', grid_search.best_params_)\n",
    "    \n",
    "    if show_tree:\n",
    "        tree.plot_tree(\n",
    "            model,\n",
    "            feature_names=X_train.columns,\n",
    "            class_names=['good', 'bad'],\n",
    "            filled = True\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_and_evaluate(model, X_test, y_test):\n",
    "    # Avaliação no conjunto de teste\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    recall = recall_score(y_test, y_pred, pos_label='bad')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print('Relatório:')\n",
    "    print(f'recall (bad): {recall:.2f}')\n",
    "    print(f'accuracy: {accuracy:.2f}')\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=['good', 'bad'])\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.title('Matriz de Confusão')\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['good', 'bad'], yticklabels=['good', 'bad'])\n",
    "    plt.xlabel('Predito')\n",
    "    plt.ylabel('Real')\n",
    "    plt.show()\n",
    "\n",
    "```\n",
    "\n",
    "### Preparação mínima\n",
    "\n",
    "A árvore de decisão exige uma preparação mínima dos atributos qualitativos. Os mesmo não podem ser textuais, devem ter uma representação numérica ou passível de conversão em tipo numérico. Farei essa preparação nos atributos (qualitativos) listados abaixo.\n",
    "\n",
    "\n",
    "```python\n",
    "resumo_df[resumo_df['tipo'].str.contains('qualitativa')]\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>atributo</th>\n",
    "      <th>tipo</th>\n",
    "      <th>valores faltantes</th>\n",
    "      <th>outliers</th>\n",
    "      <th>cardinalidade</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>Sex</td>\n",
    "      <td>qualitativa nominal</td>\n",
    "      <td>0</td>\n",
    "      <td>n/a</td>\n",
    "      <td>discreta (binária)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>Job</td>\n",
    "      <td>qualitativa ordinal</td>\n",
    "      <td>0</td>\n",
    "      <td>n/a</td>\n",
    "      <td>discreta</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>Housing</td>\n",
    "      <td>qualitativa nominal</td>\n",
    "      <td>0</td>\n",
    "      <td>n/a</td>\n",
    "      <td>discreta</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>Saving accounts</td>\n",
    "      <td>qualitativa ordinal</td>\n",
    "      <td>183</td>\n",
    "      <td>n/a</td>\n",
    "      <td>discreta</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>Checking account</td>\n",
    "      <td>qualitativa ordinal</td>\n",
    "      <td>394</td>\n",
    "      <td>n/a</td>\n",
    "      <td>discreta</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>8</th>\n",
    "      <td>Purpose</td>\n",
    "      <td>qualitativa nominal</td>\n",
    "      <td>0</td>\n",
    "      <td>n/a</td>\n",
    "      <td>discreta</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>9</th>\n",
    "      <td>Risk</td>\n",
    "      <td>qualitativa nominal</td>\n",
    "      <td>0</td>\n",
    "      <td>n/a</td>\n",
    "      <td>discreta (binária)</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "### Funções de preparação dos dados\n",
    "\n",
    "\n",
    "```python\n",
    "def prepare_sex(df):\n",
    "    df_preparado = df.copy()\n",
    "    df_preparado.loc[df_preparado['Sex'] == 'male', 'Sex'] = False\n",
    "    df_preparado.loc[df_preparado['Sex'] == 'female', 'Sex'] = True\n",
    "    df_preparado['Sex'] = df_preparado['Sex'].astype(bool)\n",
    "    return df_preparado\n",
    "\n",
    "# Job -> Ja esta representado com numeros da forma correta\n",
    "\n",
    "def prepare_housing(df):\n",
    "    df_preparado = df.copy()\n",
    "    dummies = pd.get_dummies(df_preparado['Housing'])\n",
    "    df_preparado = pd.concat([df_preparado, dummies], axis=1)\n",
    "    df_preparado = df_preparado.drop('Housing', axis=1)\n",
    "    return df_preparado\n",
    "\n",
    "def prepare_saving_accounts(df):\n",
    "    # 0 = little, 1 = moderate, 2 = quite rich, 3 = rich\n",
    "    df_preparado = df.copy()\n",
    "    df_preparado.loc[df_preparado['Saving accounts'] == 'little', 'Saving accounts'] = 0\n",
    "    df_preparado.loc[df_preparado['Saving accounts'] == 'moderate', 'Saving accounts'] = 1\n",
    "    df_preparado.loc[df_preparado['Saving accounts'] == 'quite rich', 'Saving accounts'] = 2\n",
    "    df_preparado.loc[df_preparado['Saving accounts'] == 'rich', 'Saving accounts'] = 3\n",
    "    return df_preparado\n",
    "\n",
    "def prepare_checking_account(df):\n",
    "    # 0 = little, 1 = moderate, 2 = rich\n",
    "    df_preparado = df.copy()\n",
    "    df_preparado.loc[df_preparado['Checking account'] == 'little', 'Checking account'] = 0\n",
    "    df_preparado.loc[df_preparado['Checking account'] == 'moderate', 'Checking account'] = 1\n",
    "    df_preparado.loc[df_preparado['Checking account'] == 'rich', 'Checking account'] = 2\n",
    "    return df_preparado\n",
    "\n",
    "def prepare_purpose(df):\n",
    "    df_preparado = df.copy()\n",
    "    dummies = pd.get_dummies(df_preparado['Purpose'])\n",
    "    df_preparado = pd.concat([df_preparado, dummies], axis=1)\n",
    "    df_preparado = df_preparado.drop('Purpose', axis=1)\n",
    "    return df_preparado\n",
    "\n",
    "def prepare_all(df_preparado):\n",
    "    df_preparado = prepare_sex(df_preparado)\n",
    "    df_preparado = prepare_housing(df_preparado)\n",
    "    df_preparado = prepare_saving_accounts(df_preparado)\n",
    "    df_preparado = prepare_checking_account(df_preparado)\n",
    "    df_preparado = prepare_purpose(df_preparado)\n",
    "    return df_preparado\n",
    "\n",
    "df_preparado = prepare_all(df.copy())\n",
    "df_preparado.head()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Age</th>\n",
    "      <th>Sex</th>\n",
    "      <th>Job</th>\n",
    "      <th>Saving accounts</th>\n",
    "      <th>Checking account</th>\n",
    "      <th>Credit amount</th>\n",
    "      <th>Duration</th>\n",
    "      <th>Risk</th>\n",
    "      <th>free</th>\n",
    "      <th>own</th>\n",
    "      <th>rent</th>\n",
    "      <th>business</th>\n",
    "      <th>car</th>\n",
    "      <th>domestic appliances</th>\n",
    "      <th>education</th>\n",
    "      <th>furniture/equipment</th>\n",
    "      <th>radio/TV</th>\n",
    "      <th>repairs</th>\n",
    "      <th>vacation/others</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>67</td>\n",
    "      <td>False</td>\n",
    "      <td>2</td>\n",
    "      <td>NaN</td>\n",
    "      <td>0</td>\n",
    "      <td>1169</td>\n",
    "      <td>6</td>\n",
    "      <td>good</td>\n",
    "      <td>False</td>\n",
    "      <td>True</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>True</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>22</td>\n",
    "      <td>True</td>\n",
    "      <td>2</td>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>5951</td>\n",
    "      <td>48</td>\n",
    "      <td>bad</td>\n",
    "      <td>False</td>\n",
    "      <td>True</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>True</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>49</td>\n",
    "      <td>False</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>NaN</td>\n",
    "      <td>2096</td>\n",
    "      <td>12</td>\n",
    "      <td>good</td>\n",
    "      <td>False</td>\n",
    "      <td>True</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>True</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>45</td>\n",
    "      <td>False</td>\n",
    "      <td>2</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>7882</td>\n",
    "      <td>42</td>\n",
    "      <td>good</td>\n",
    "      <td>True</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>True</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>53</td>\n",
    "      <td>False</td>\n",
    "      <td>2</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>4870</td>\n",
    "      <td>24</td>\n",
    "      <td>bad</td>\n",
    "      <td>True</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>True</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "### Avaliação\n",
    "\n",
    "Quero que o modelo acerte mais na classificação de pessoas que são más (`bad`) devedoras. Isso para garantir que o modelo não diga que uma pessoa é boa devedora, i.e., pagará seu empréstimo, quando a pessoa não é e não pagará. Dessa forma, diminui as chances de sair no prejuízo.\n",
    "Claro que não posso deixar de observar também a classificação dos bons (`good`) devedores, pois se o modelo os classifica errado, é dinheiro que deixa de entrar.\n",
    "\n",
    "### Sem Tratamento dos Dados\n",
    "\n",
    "\n",
    "```python\n",
    "def execute_experiment(df, show_best_params=False, show_tree=False):\n",
    "    X = df.drop('Risk', axis=1)\n",
    "    y = df['Risk']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    scorer = make_scorer(recall_score, pos_label='bad')\n",
    "\n",
    "    model = trained_model(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        scorer,\n",
    "        show_best_params=show_best_params,\n",
    "        show_tree=show_tree\n",
    "    )\n",
    "    predict_and_evaluate(model, X_test, y_test)\n",
    "\n",
    "df_preparado = prepare_all(df.copy())\n",
    "execute_experiment(df_preparado, show_tree=True)\n",
    "```\n",
    "\n",
    "\n",
    "    \n",
    "![png](analise1_files/analise1_69_0.png)\n",
    "    \n",
    "\n",
    "\n",
    "    Relatório:\n",
    "    recall (bad): 0.50\n",
    "    accuracy: 0.65\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "![png](analise1_files/analise1_69_2.png)\n",
    "    \n",
    "\n",
    "\n",
    "Sem tratamento de dados, temos um `recall` de $0.5$ e `accuracy` de $0.65$. Não foi um resultado promissor, mas sinto que pode melhorar.\n",
    "\n",
    "### Limpando os Dados\n",
    "\n",
    "Como não há *outliers* nessa base, não preciso me preocupar com o tratamento desse tipo de problema. Mas há $183$ valores faltantes para `Saving accounts` e $394$ para `Checking account`.\n",
    "\n",
    "#### Removendo Linhas\n",
    "\n",
    "Pela base de dados ter poucos registros ($1000$), acredito que seguir pela estratégia de remoção de linhas irá mais atrapalhar o modelo do que ajudar, mas não custa fazer a avaliação. Para isso, irei avaliar dois pontos que me preocupam:\n",
    "\n",
    "1. Quantos registros terei da base se remover registros com valores faltantes?\n",
    "2. A proporcionalidade entre as classes de `Risk` se manterá?\n",
    "\n",
    "Farei a avaliação desses dois pontos para os seguintes cenários:\n",
    "1. Removendo o atributo `Saving accounts`\n",
    "2. Removendo o atributo `Checking account`\n",
    "3. Removendo ambos.\n",
    "\n",
    "\n",
    "```python\n",
    "total = len(df)\n",
    "risk_good = len(df[df['Risk'] == 'good'])\n",
    "risk_bad = len(df[df['Risk'] == 'bad'])\n",
    "\n",
    "df_sem_saving = df.dropna(subset=['Saving accounts'])\n",
    "risk_good_sem_saving = len(df_sem_saving[df_sem_saving['Risk'] == 'good'])\n",
    "risk_bad_sem_saving = len(df_sem_saving[df_sem_saving['Risk'] == 'bad'])\n",
    "\n",
    "df_sem_checking = df.dropna(subset=['Checking account'])\n",
    "risk_good_sem_checking = len(df_sem_checking[df_sem_checking['Risk'] == 'good'])\n",
    "risk_bad_sem_cheking = len(df_sem_checking[df_sem_checking['Risk'] == 'bad'])\n",
    "\n",
    "df_sem_ambos = df.dropna(subset=['Saving accounts', 'Checking account'])\n",
    "risk_good_sem_ambos = len(df_sem_ambos[df_sem_ambos['Risk'] == 'good'])\n",
    "risk_bad_sem_ambos = len(df_sem_ambos[df_sem_ambos['Risk'] == 'bad'])\n",
    "\n",
    "rotulos = ('Base Original', 'Cenário 1', 'Cenário 2', 'Cenário 3')\n",
    "risks = {\n",
    "    'good': [risk_good, risk_good_sem_saving, risk_good_sem_checking, risk_good_sem_ambos],\n",
    "    'bad': [risk_bad, risk_bad_sem_saving, risk_bad_sem_cheking, risk_bad_sem_ambos]\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylim(0, 1200)\n",
    "\n",
    "bottom = np.zeros(4)\n",
    "\n",
    "for risk, values in risks.items():\n",
    "    p = ax.bar(rotulos, values, label=risk, bottom=bottom)\n",
    "    bottom += values\n",
    "    ax.bar_label(p, label_type='center')\n",
    "\n",
    "for idx, total in enumerate(bottom):\n",
    "    ax.text(idx, total + 60, f'{int(total)} registros', ha='center', va='bottom')\n",
    "    good_percentage = (risks['good'][idx] / total) * 100\n",
    "    bad_percentage = (risks['bad'][idx] / total) * 100\n",
    "    ax.text(idx, total + 10, f'{good_percentage:.2f}% : {bad_percentage:.2f}%', ha='center', va='bottom',)\n",
    "\n",
    "ax.set_title('Exclusão de linhas com valores faltantes')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "\n",
    "    \n",
    "![png](analise1_files/analise1_75_0.png)\n",
    "    \n",
    "\n",
    "\n",
    "Como podemos perceber, para cada estratégia, ficamos com cada vez menos registros e a razão entre os valores do atributo `Risk` também altera consideravelmente. A única estratégia que talvez ajude será a do cenário 1, removendo os registros nulos para o atributo `Saving accounts`. Escrevo isso com bastante desconfiança, pois ainda acredito não ser uma boa estratégia, mas irei avaliá-la para ter certeza.\n",
    "\n",
    "#### Cenário 1 - Sem `Saving accounts`\n",
    "\n",
    "\n",
    "```python\n",
    "df_preparado = prepare_all(df.copy())\n",
    "df_cleaned = df_preparado.dropna(subset=['Saving accounts'])\n",
    "execute_experiment(df_cleaned, show_tree=True)\n",
    "```\n",
    "\n",
    "\n",
    "    \n",
    "![png](analise1_files/analise1_78_0.png)\n",
    "    \n",
    "\n",
    "\n",
    "    Relatório:\n",
    "    recall (bad): 0.56\n",
    "    accuracy: 0.72\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "![png](analise1_files/analise1_78_2.png)\n",
    "    \n",
    "\n",
    "\n",
    "Até que remover a coluna `Saving accounts`, ao contrário do que eu esperava, melhorou o modelo. Tanto pelo `recall` quanto pela acurácia (`accuracy`). Contudo, não irei avaliar para os demais cenários mencionados acima pelos fatores mencionados: diminuem consideravelmente a quantidade de dados e alteram a proporção das classes: `good` e `bad`.\n",
    "\n",
    "#### Missing - Moda\n",
    "\n",
    "A estratégia que irei experimentar agora será de atribuir o valor da moda aos valores faltantes. Considerando, é claro, a proporção entre as diferentes classes: `good` e `bad`.\n",
    "\n",
    "\n",
    "```python\n",
    "def fill_with_mode(df, column):\n",
    "    goods_filter = df['Risk'] == 'good'\n",
    "    bads_filter = df['Risk'] == 'bad'\n",
    "\n",
    "    goods = df[goods_filter]\n",
    "    bads = df[bads_filter]\n",
    "\n",
    "    good_mode = goods[column].mode()[0]\n",
    "    bad_mode = bads[column].mode()[0]\n",
    "\n",
    "    df.loc[goods_filter, column] = df.loc[goods_filter, column].fillna(good_mode)\n",
    "    df.loc[bads_filter, column] = df.loc[bads_filter, column].fillna(bad_mode)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_mode_filled = prepare_all(df.copy())\n",
    "df_mode_filled = fill_with_mode(df_mode_filled, 'Saving accounts')\n",
    "df_mode_filled = fill_with_mode(df_mode_filled, 'Checking account')\n",
    "\n",
    "execute_experiment(df_mode_filled, show_tree=True)\n",
    "```\n",
    "\n",
    "    /tmp/ipykernel_1519998/2571373263.py:11: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
    "      df.loc[goods_filter, column] = df.loc[goods_filter, column].fillna(good_mode)\n",
    "    /tmp/ipykernel_1519998/2571373263.py:12: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
    "      df.loc[bads_filter, column] = df.loc[bads_filter, column].fillna(bad_mode)\n",
    "    /tmp/ipykernel_1519998/2571373263.py:11: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
    "      df.loc[goods_filter, column] = df.loc[goods_filter, column].fillna(good_mode)\n",
    "    /tmp/ipykernel_1519998/2571373263.py:12: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
    "      df.loc[bads_filter, column] = df.loc[bads_filter, column].fillna(bad_mode)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "![png](analise1_files/analise1_82_1.png)\n",
    "    \n",
    "\n",
    "\n",
    "    Relatório:\n",
    "    recall (bad): 0.63\n",
    "    accuracy: 0.79\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "![png](analise1_files/analise1_82_3.png)\n",
    "    \n",
    "\n",
    "\n",
    "Com esse tratamento, o modelo melhorou consideravelmente, tendo aumentado o `recall` para $0.63$ e a acurácia para $0.79$. Além disso, é perceptível, também, como a profuncidade e densidade da árvore mudaram e com isso ela ficou mais simples. Tornando o uso do modelo mais rápido, além de melhor (pelo menos em comparação com os casos anteriores).\n",
    "\n",
    "Me dou por satisfeito com esse resultado após a limpeza dos dados.\n",
    "\n",
    "# Exercício 2\n",
    "\n",
    "Faça uma análise de seleção de variáveis utilizando os métodos que julgar necessários, considerando o tipo de dado. Abaixo uma tabela é indicada para que possa usar como inspiração avaliação de importância composta dos métodos que considerar. \n",
    "\n",
    "## Método 1 - Árvore de Decisão\n",
    "\n",
    "\n",
    "```python\n",
    "df_preparado = prepare_all(df.copy())\n",
    "\n",
    "X = df_preparado.drop('Risk', axis=1)\n",
    "y = df_preparado['Risk']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "tree_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "tree_importances.sort_values(ascending=False)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Credit amount          0.195448\n",
    "    Age                    0.189478\n",
    "    Duration               0.155385\n",
    "    Checking account       0.150071\n",
    "    Saving accounts        0.060795\n",
    "    Job                    0.042556\n",
    "    car                    0.032372\n",
    "    furniture/equipment    0.029035\n",
    "    Sex                    0.026972\n",
    "    radio/TV               0.025156\n",
    "    own                    0.018321\n",
    "    education              0.018052\n",
    "    business               0.013373\n",
    "    rent                   0.012579\n",
    "    repairs                0.010924\n",
    "    free                   0.009959\n",
    "    domestic appliances    0.005291\n",
    "    vacation/others        0.004233\n",
    "    dtype: float64\n",
    "\n",
    "\n",
    "\n",
    "## Método 2 - ANOVA\n",
    "\n",
    "\n",
    "```python\n",
    "df_preparado = prepare_all(df.copy())\n",
    "\n",
    "df_preparado.dropna(inplace=True)\n",
    "\n",
    "X = df_preparado.drop('Risk', axis=1)\n",
    "y = df_preparado['Risk']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "anova_selector = SelectKBest(score_func=f_classif, k='all')\n",
    "anova_selector.fit(X_train, y_train)\n",
    "anova_scores = pd.Series(anova_selector.scores_, index=X.columns)\n",
    "anova_scores.sort_values(ascending=False)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Duration               38.794960\n",
    "    Credit amount          10.636884\n",
    "    Saving accounts         9.207652\n",
    "    Checking account        8.922135\n",
    "    own                     6.505199\n",
    "    rent                    5.108268\n",
    "    Sex                     4.150256\n",
    "    education               2.691121\n",
    "    repairs                 1.826396\n",
    "    radio/TV                1.297288\n",
    "    Age                     1.235157\n",
    "    car                     1.122064\n",
    "    free                    0.795872\n",
    "    vacation/others         0.717230\n",
    "    Job                     0.666234\n",
    "    domestic appliances     0.077968\n",
    "    furniture/equipment     0.041039\n",
    "    business                0.016375\n",
    "    dtype: float64\n",
    "\n",
    "\n",
    "\n",
    "## Qui-quadrado ($\\chi^2$)\n",
    "\n",
    "\n",
    "```python\n",
    "df_preparado = prepare_all(df.copy())\n",
    "\n",
    "df_preparado.dropna(inplace=True)\n",
    "\n",
    "X = df_preparado.drop('Risk', axis=1)\n",
    "y = df_preparado['Risk']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "chi2_selector = SelectKBest(score_func=chi2, k='all')\n",
    "chi2_selector.fit(X_train, y_train)\n",
    "chi2_scores = pd.Series(chi2_selector.scores_, index=X.columns)\n",
    "chi2_scores.sort_values(ascending=False)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Credit amount          27156.692405\n",
    "    Duration                 262.452894\n",
    "    Saving accounts           15.568178\n",
    "    Checking account           6.117038\n",
    "    Age                        5.123471\n",
    "    rent                       4.109880\n",
    "    Sex                        2.782348\n",
    "    education                  2.538483\n",
    "    own                        2.052624\n",
    "    repairs                    1.787721\n",
    "    radio/TV                   0.990968\n",
    "    car                        0.736138\n",
    "    vacation/others            0.707366\n",
    "    free                       0.694816\n",
    "    Job                        0.165251\n",
    "    domestic appliances        0.077202\n",
    "    furniture/equipment        0.033026\n",
    "    business                   0.014638\n",
    "    dtype: float64\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "ranking_df = pd.DataFrame({\n",
    "    'Decision Tree': tree_importances,\n",
    "    'ANOVA': anova_scores,\n",
    "    'Chi2': chi2_scores\n",
    "})\n",
    "\n",
    "ranking_df_ranked = ranking_df.rank(ascending=False)\n",
    "ranking_df_ranked = ranking_df_ranked.sort_values(by=['Decision Tree', 'ANOVA', 'Chi2'], ascending=True)\n",
    "```\n",
    "\n",
    "Após a execução dos seletores acima, temos as seguintes importâncias dos atributos com base em cada seletor.\n",
    "\n",
    "\n",
    "```python\n",
    "ranking_df_ranked\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Decision Tree</th>\n",
    "      <th>ANOVA</th>\n",
    "      <th>Chi2</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>Credit amount</th>\n",
    "      <td>1.0</td>\n",
    "      <td>2.0</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Age</th>\n",
    "      <td>2.0</td>\n",
    "      <td>11.0</td>\n",
    "      <td>5.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Duration</th>\n",
    "      <td>3.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>2.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Checking account</th>\n",
    "      <td>4.0</td>\n",
    "      <td>4.0</td>\n",
    "      <td>4.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Saving accounts</th>\n",
    "      <td>5.0</td>\n",
    "      <td>3.0</td>\n",
    "      <td>3.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Job</th>\n",
    "      <td>6.0</td>\n",
    "      <td>15.0</td>\n",
    "      <td>15.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>car</th>\n",
    "      <td>7.0</td>\n",
    "      <td>12.0</td>\n",
    "      <td>12.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>furniture/equipment</th>\n",
    "      <td>8.0</td>\n",
    "      <td>17.0</td>\n",
    "      <td>17.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Sex</th>\n",
    "      <td>9.0</td>\n",
    "      <td>7.0</td>\n",
    "      <td>7.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>radio/TV</th>\n",
    "      <td>10.0</td>\n",
    "      <td>10.0</td>\n",
    "      <td>11.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>own</th>\n",
    "      <td>11.0</td>\n",
    "      <td>5.0</td>\n",
    "      <td>9.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>education</th>\n",
    "      <td>12.0</td>\n",
    "      <td>8.0</td>\n",
    "      <td>8.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>business</th>\n",
    "      <td>13.0</td>\n",
    "      <td>18.0</td>\n",
    "      <td>18.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>rent</th>\n",
    "      <td>14.0</td>\n",
    "      <td>6.0</td>\n",
    "      <td>6.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>repairs</th>\n",
    "      <td>15.0</td>\n",
    "      <td>9.0</td>\n",
    "      <td>10.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>free</th>\n",
    "      <td>16.0</td>\n",
    "      <td>13.0</td>\n",
    "      <td>14.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>domestic appliances</th>\n",
    "      <td>17.0</td>\n",
    "      <td>16.0</td>\n",
    "      <td>16.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>vacation/others</th>\n",
    "      <td>18.0</td>\n",
    "      <td>14.0</td>\n",
    "      <td>13.0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "Avaliando a tabela acima, podemos ver a importância de cada atributo e selecionar apenas as ($n$) primeiras $^1$ para treinamento e execução de algum modelo de *machine learning*. Isso para que consideremos apenas os atributos que são, de fato, úteis para o aprendizado e não causem ruídos.\n",
    "\n",
    "$_{ \\text{1. } n \\text{ deve ser avaliado para cada cenário }}$\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
